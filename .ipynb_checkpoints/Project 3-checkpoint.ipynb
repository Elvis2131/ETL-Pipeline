{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "                .appName(\"Stack Overflow Data Wrangling\")\n",
    "                .config(\"spark.jars\", \"C:\\\\Users\\\\ELVIS LARTEY\\\\Documents\\\\Blossom Works\\\\postgresql-42.2.8.jar\") \n",
    "                .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file i.e question,answers and users into thei respective dataframe.\n",
    "questions = spark.read.csv(\"C:\\\\Users\\\\ELVIS LARTEY\\\\Documents\\\\Blossom Works\\\\stackoverflow\\\\questions.csv\", header=True, inferSchema=True)\n",
    "users = spark.read.csv(\"C:\\\\Users\\\\ELVIS LARTEY\\\\Documents\\\\Blossom Works\\\\stackoverflow\\\\users.csv\", header=True, inferSchema=True)\n",
    "answers = spark.read.csv(\"C:\\\\Users\\\\ELVIS LARTEY\\\\Documents\\\\Blossom Works\\\\stackoverflow\\\\answers.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column ids\n",
    "questions = questions.withColumnRenamed('id','answer_id')\n",
    "users = users.withColumnRenamed('id','user_id')\n",
    "answers = answers.withColumnRenamed('id', 'answer_id')\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the dataframe to a temporary sql table to run queries on.\n",
    "users.registerTempTable('user_tbl')\n",
    "result = spark.sql(\"SELECT display_name,location from user_tbl WHERE location LIKE '%Canada%'\")\n",
    "\n",
    "#join the results of the query to the questions table.\n",
    "joined_df = questions.join(result)\n",
    "joined_df.registerTempTable(\"joined_tbl\")\n",
    "\n",
    "# Run query to get columns where the view_count >= 20 and show the results\n",
    "get_view_count = spark.sql(\"SELECT * from joined_tbl where view_count >= 20\")\n",
    "get_view_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the query results to the answers dataframe\n",
    "comp_answer = answers.join(get_view_count).select(get_view_count.answer_id,get_view_count.user_id, answers.question_id,\n",
    "                                                 get_view_count.created_at,answers.body, get_view_count.accepted_answer_id,\n",
    "                                                 get_view_count.view_count,get_view_count.score,get_view_count.comment_count,get_view_count.location,get_view_count.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the generated results in a postgresDB\n",
    "comp_answer.write.format(\"jdbc\").options(\n",
    "    url='jdbc:postgresql://localhost/postgres',\n",
    "    driver='org.postgresql.Driver',\n",
    "    user='postgres',\n",
    "    password='Secondary123.',\n",
    "    dbtable='stackoverflow_filtered.results'\n",
    ").save(mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
